# The Spark Workshop

# Chapter 5
# DataFrames with Spark

# By Craig Covey


df.columns

df.columns[2]
df.columns[2:5]

df.dtypes

df.select(df.id).take(5)

string_id_df = df.select(df.id.cast("string"))
string_id_df.take(5)

string_id_df.schema

df.select(df.id.cast("string").alias('new_id')).show(5)

# Drop Columns

df.drop("ip_address")
df.drop("comments", "registration_dttm")

df.drop(df.first_name)
df.drop(df.first_name).drop(df.title)

# Rename Columns

print(df.columns)
df_renamed = df.withColumnRenamed("title", "role")
print(df_renamed.columns)

# Exercise 5.20

df.withColumn("append_id", df["id"] + 10).select("id", "append_id").show(5)



from pyspark.sql.functions import lit
server_df = df.withColumn("constant_string", lit("generated by server")).select("id", "constant_string")
server_df.show(5)
server_df.printSchema()

# Exercise 5.21

from pyspark.sql.functions import col, lower, upper

df.withColumn("FIRST_NAME_UPPER", upper(col("first_name"))).select("id", "first_name", "FIRST_NAME_UPPER").show(3)

# Exercise 5.22

from pyspark.sql.types import DateType

registration_df = df.withColumn("registration_date", df.registration_dttm.cast(DateType())).select("id", "registration_dttm", "registration_date")

registration_df.show(3)
registration_df.printSchema()
