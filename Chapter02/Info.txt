The statistics and index files for the October 2019 crawl archive can be found at https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-43/index.html
The two links warc.paths.gz and wet.paths.gz on this page lead to the download locations for the index files of the WARC and WET records.
Each index file contains 56000 lines and each line represents a URL fragment that points to a gzipped file which contains a subset of the entire crawl, so the entire crawl content for October is spread across 56000 files.
To obtain a valid URL, the lines need to be prefixed by https://commoncrawl.s3.amazonaws.com/ or s3://commoncrawl/ .
For example, the full download paths for the first WARC and WET files from the first line of the corresponding index/path files would be
https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-43/segments/1570986647517.11/warc/CC-MAIN-20191013195541-20191013222541-00000.warc.gz
https://commoncrawl.s3.amazonaws.com/crawl-data/CC-MAIN-2019-43/segments/1570986647517.11/wet/CC-MAIN-20191013195541-20191013222541-00000.warc.wet.gz


The following sources show how the files can be parsed/converted to structured data:
Scala:
The-Spark-Workshop/Chapter02/scala/packt2/spark/ParsingWet.scala => WET files which contain plain text
The-Spark-Workshop/Chapter02/scala/packt2/spark/ParsingWarc.scala => WARC files which contain raw HTML data + meta info

Python:
The-Spark-Workshop/Chapter02/python/packt2/spark/parsing_wet.py => WET files which contain plain text
The-Spark-Workshop/Chapter02/python/packt2/spark/parsing_warc.py => WARC files which contain raw HTML data + meta info